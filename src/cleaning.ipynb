{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e63b08c5",
   "metadata": {},
   "source": [
    "# 2. Cleaning the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67180b8",
   "metadata": {},
   "source": [
    "## 2.1 Preliminar Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "id": "5156d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from fuzzywuzzy import process\n",
    "import pycountry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "id": "7fd8b14a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case Number         Date    Year        Type Country        Area  \\\n",
       "0  2018.06.25  25-Jun-2018  2018.0     Boating     USA  California   \n",
       "1  2018.06.18  18-Jun-2018  2018.0  Unprovoked     USA     Georgia   \n",
       "2  2018.06.09  09-Jun-2018  2018.0     Invalid     USA      Hawaii   \n",
       "\n",
       "                         Location  Activity             Name Sex   ...  \\\n",
       "0     Oceanside, San Diego County  Paddling      Julie Wolfe    F  ...   \n",
       "1  St. Simon Island, Glynn County  Standing  Adyson McNeely     F  ...   \n",
       "2                    Habush, Oahu   Surfing      John Denges    M  ...   \n",
       "\n",
       "      Species           Investigator or Source                     pdf  \\\n",
       "0  White shark                R. Collier, GSAF    2018.06.25-Wolfe.pdf   \n",
       "1          NaN  K.McMurray, TrackingSharks.com  2018.06.18-McNeely.pdf   \n",
       "2          NaN  K.McMurray, TrackingSharks.com   2018.06.09-Denges.pdf   \n",
       "\n",
       "                                        href formula  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href Case Number.1  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.25   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.18   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.09   \n",
       "\n",
       "  Case Number.2 original order Unnamed: 22 Unnamed: 23  \n",
       "0    2018.06.25         6303.0         NaN         NaN  \n",
       "1    2018.06.18         6302.0         NaN         NaN  \n",
       "2    2018.06.09         6301.0         NaN         NaN  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 1211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data():\n",
    "    \n",
    "    #Importing CSV\n",
    "    file_path = '/Users/mairagutierrez/Documents/Ironhack/PROJECTS/project--I/data/attacks.csv'\n",
    "    \n",
    "    # Try reading the file with a different encoding\n",
    "    data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "    return data\n",
    "    \n",
    "data = get_data()\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "id": "785aeef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex_</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal_(Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species_</th>\n",
       "      <th>Investigator_or_Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href_formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>18h00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>14h00  -15h00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>48</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6301.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case_Number         Date    Year        Type Country        Area  \\\n",
       "0  2018.06.25  25-Jun-2018  2018.0     Boating     USA  California   \n",
       "1  2018.06.18  18-Jun-2018  2018.0  Unprovoked     USA     Georgia   \n",
       "2  2018.06.09  09-Jun-2018  2018.0     Invalid     USA      Hawaii   \n",
       "\n",
       "                         Location  Activity             Name Sex_ Age  \\\n",
       "0     Oceanside, San Diego County  Paddling      Julie Wolfe    F  57   \n",
       "1  St. Simon Island, Glynn County  Standing  Adyson McNeely     F  11   \n",
       "2                    Habush, Oahu   Surfing      John Denges    M  48   \n",
       "\n",
       "                                              Injury Fatal_(Y/N)  \\\n",
       "0  No injury to occupant, outrigger canoe and pad...           N   \n",
       "1                         Minor injury to left thigh           N   \n",
       "2       Injury to left lower leg from surfboard skeg           N   \n",
       "\n",
       "            Time     Species_          Investigator_or_Source  \\\n",
       "0          18h00  White shark                R. Collier, GSAF   \n",
       "1  14h00  -15h00          NaN  K.McMurray, TrackingSharks.com   \n",
       "2          07h45          NaN  K.McMurray, TrackingSharks.com   \n",
       "\n",
       "                      pdf                                       href_formula  \\\n",
       "0    2018.06.25-Wolfe.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  2018.06.18-McNeely.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2   2018.06.09-Denges.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href  original_order  \n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...          6303.0  \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...          6302.0  \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...          6301.0  "
      ]
     },
     "execution_count": 1212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pre_cleaning(data):\n",
    "    \n",
    "    #dropping columns with 99% missing values and the ones that aren't relevant for my research\n",
    "    pre_cleaned_data = data.drop(columns = ['Unnamed: 22', 'Unnamed: 23', 'Case Number.1', 'Case Number.2'], axis = 1)\n",
    "    \n",
    "    #dropping all rows with NaN in every column\n",
    "    pre_cleaned_data = pre_cleaned_data.dropna(how=\"all\")\n",
    "    \n",
    "    #Remove spaces in column titles\n",
    "    pre_cleaned_data.columns = pre_cleaned_data.columns.str.replace(' ','_')\n",
    "    \n",
    "    return pre_cleaned_data\n",
    "\n",
    "pre_cleaned_data = pre_cleaning(data)\n",
    "pre_cleaned_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "id": "a0179e1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case_Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex_', 'Age', 'Injury', 'Fatal_(Y/N)', 'Time',\n",
       "       'Species_', 'Investigator_or_Source', 'pdf', 'href_formula', 'href',\n",
       "       'original_order'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#New data columns names without spaces\n",
    "pre_cleaned_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66f8eb",
   "metadata": {},
   "source": [
    "## 2.2 Cleaning Year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "id": "19b2b41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex_</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal_(Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species_</th>\n",
       "      <th>Investigator_or_Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href_formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>18h00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>14h00  -15h00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>48</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6301.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case_Number         Date  Year        Type Country        Area  \\\n",
       "0  2018.06.25  25-Jun-2018  2018     Boating     USA  California   \n",
       "1  2018.06.18  18-Jun-2018  2018  Unprovoked     USA     Georgia   \n",
       "2  2018.06.09  09-Jun-2018  2018     Invalid     USA      Hawaii   \n",
       "\n",
       "                         Location  Activity             Name Sex_ Age  \\\n",
       "0     Oceanside, San Diego County  Paddling      Julie Wolfe    F  57   \n",
       "1  St. Simon Island, Glynn County  Standing  Adyson McNeely     F  11   \n",
       "2                    Habush, Oahu   Surfing      John Denges    M  48   \n",
       "\n",
       "                                              Injury Fatal_(Y/N)  \\\n",
       "0  No injury to occupant, outrigger canoe and pad...           N   \n",
       "1                         Minor injury to left thigh           N   \n",
       "2       Injury to left lower leg from surfboard skeg           N   \n",
       "\n",
       "            Time     Species_          Investigator_or_Source  \\\n",
       "0          18h00  White shark                R. Collier, GSAF   \n",
       "1  14h00  -15h00          NaN  K.McMurray, TrackingSharks.com   \n",
       "2          07h45          NaN  K.McMurray, TrackingSharks.com   \n",
       "\n",
       "                      pdf                                       href_formula  \\\n",
       "0    2018.06.25-Wolfe.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  2018.06.18-McNeely.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2   2018.06.09-Denges.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href  original_order  \n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...          6303.0  \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...          6302.0  \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...          6301.0  "
      ]
     },
     "execution_count": 1214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.2 # Casting Year data type from float to integer\n",
    "pre_cleaned_data['Year'] = pre_cleaned_data['Year'].fillna(0).astype(int) \n",
    "cleaned_data = pre_cleaned_data\n",
    "\n",
    "# Filter dataframe with data over 1900 as this is data relevant to my research\n",
    "cleaned_data = pre_cleaned_data[(cleaned_data['Year'] >= 1900) & (cleaned_data['Year']<= 2018) ]\n",
    "cleaned_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8265555b",
   "metadata": {},
   "source": [
    "## 2.3 Cleaning Case Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "id": "bae9861a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Extracted_Month</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal_(Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species_</th>\n",
       "      <th>Investigator_or_Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href_formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>18h00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>14h00  -15h00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6301.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case_Number         Date  Year Extracted_Month        Type Country  \\\n",
       "0  2018.06.25  25-Jun-2018  2018              06     Boating     USA   \n",
       "1  2018.06.18  18-Jun-2018  2018              06  Unprovoked     USA   \n",
       "2  2018.06.09  09-Jun-2018  2018              06     Invalid     USA   \n",
       "\n",
       "         Area                        Location  Activity             Name  ...  \\\n",
       "0  California     Oceanside, San Diego County  Paddling      Julie Wolfe  ...   \n",
       "1     Georgia  St. Simon Island, Glynn County  Standing  Adyson McNeely   ...   \n",
       "2      Hawaii                    Habush, Oahu   Surfing      John Denges  ...   \n",
       "\n",
       "  Age                                             Injury Fatal_(Y/N)  \\\n",
       "0  57  No injury to occupant, outrigger canoe and pad...           N   \n",
       "1  11                         Minor injury to left thigh           N   \n",
       "2  48       Injury to left lower leg from surfboard skeg           N   \n",
       "\n",
       "            Time     Species_          Investigator_or_Source  \\\n",
       "0          18h00  White shark                R. Collier, GSAF   \n",
       "1  14h00  -15h00          NaN  K.McMurray, TrackingSharks.com   \n",
       "2          07h45          NaN  K.McMurray, TrackingSharks.com   \n",
       "\n",
       "                      pdf                                       href_formula  \\\n",
       "0    2018.06.25-Wolfe.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  2018.06.18-McNeely.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2   2018.06.09-Denges.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href original_order  \n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...         6303.0  \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...         6302.0  \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...         6301.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 1216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing any letter at the end of the date and any spaces.\n",
    "cleaned_data['Case_Number'] = cleaned_data['Case_Number'].str.strip().str.replace(r'[A-Za-z]$', '', regex=True)\n",
    "\n",
    "# Extracting the year from the 'Case_Number' column and creating a new column 'Extracted_Year'\n",
    "#cleaned_data = cleaned_data.assign(Extracted_Year=cleaned_data['Case_Number'].str[:4])\n",
    "\n",
    "# Extracting the month from the 'Case_Number' column\n",
    "cleaned_data = cleaned_data.assign(Extracted_Month=cleaned_data['Case_Number'].str.extract(r'\\.(\\d{2})\\.'))\n",
    "\n",
    "\n",
    "# Reordering columns \n",
    "cleaned_data = cleaned_data[['Case_Number','Date', 'Year','Extracted_Month','Type', 'Country', 'Area', 'Location',\n",
    "       'Activity', 'Name', 'Sex_', 'Age', 'Injury', 'Fatal_(Y/N)', 'Time','Species_', 'Investigator_or_Source', 'pdf', 'href_formula', 'href','original_order']]\n",
    "\n",
    "cleaned_data.head(3)                                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ea6c16",
   "metadata": {},
   "source": [
    "## 2.4 Cleaning Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "id": "1436ab8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ['Boating' 'Unprovoked' 'Invalid' 'Provoked' 'Questionable' 'Sea Disaster'\n",
      " nan 'Boat' 'Boatomg'] 8\n"
     ]
    }
   ],
   "source": [
    "#TYPE\n",
    "nat_count_type = cleaned_data['Type'].isna().sum()\n",
    "uniq_val_type = cleaned_data['Type'].unique()\n",
    "num_uniq_type = cleaned_data['Type'].nunique()\n",
    "print(nat_count_type, uniq_val_type, num_uniq_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "id": "7551b174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Extracted_Month</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal_(Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species_</th>\n",
       "      <th>Investigator_or_Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href_formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>18h00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>14h00  -15h00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6301.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case_Number         Date  Year Extracted_Month        Type Country  \\\n",
       "0  2018.06.25  25-Jun-2018  2018              06     Boating     USA   \n",
       "1  2018.06.18  18-Jun-2018  2018              06  Unprovoked     USA   \n",
       "2  2018.06.09  09-Jun-2018  2018              06     Invalid     USA   \n",
       "\n",
       "         Area                        Location  Activity             Name  ...  \\\n",
       "0  California     Oceanside, San Diego County  Paddling      Julie Wolfe  ...   \n",
       "1     Georgia  St. Simon Island, Glynn County  Standing  Adyson McNeely   ...   \n",
       "2      Hawaii                    Habush, Oahu   Surfing      John Denges  ...   \n",
       "\n",
       "  Age                                             Injury Fatal_(Y/N)  \\\n",
       "0  57  No injury to occupant, outrigger canoe and pad...           N   \n",
       "1  11                         Minor injury to left thigh           N   \n",
       "2  48       Injury to left lower leg from surfboard skeg           N   \n",
       "\n",
       "            Time     Species_          Investigator_or_Source  \\\n",
       "0          18h00  White shark                R. Collier, GSAF   \n",
       "1  14h00  -15h00          NaN  K.McMurray, TrackingSharks.com   \n",
       "2          07h45          NaN  K.McMurray, TrackingSharks.com   \n",
       "\n",
       "                      pdf                                       href_formula  \\\n",
       "0    2018.06.25-Wolfe.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  2018.06.18-McNeely.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2   2018.06.09-Denges.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href original_order  \n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...         6303.0  \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...         6302.0  \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...         6301.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 1218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Removing spaces at the beginning and the end of the word\n",
    "cleaned_data['Type'] = cleaned_data['Type'].str.strip()\n",
    "\n",
    "# 2) Converting all values to lower case\n",
    "cleaned_data['Type'] = cleaned_data['Type'].str.lower()\n",
    "\n",
    "# 3) Grouping the values by specified categories\n",
    "cleaned_data['Type'] = cleaned_data['Type'].replace({\n",
    "    r'.*boat.*': 'boating',  # Including all values that have \"boat\" anywhere in the string\n",
    "    'invalid': 'invalid',\n",
    "    'provoked': 'provoked',\n",
    "    'questionable': 'invalid',\n",
    "    'unprovoked': 'unprovoked',\n",
    "    'sea disaster': 'sea disaster'\n",
    "}, regex=True)\n",
    "\n",
    "cleaned_data['Type'] = cleaned_data['Type'].str.capitalize()\n",
    "cleaned_data.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f7f2b9",
   "metadata": {},
   "source": [
    "## 2.5 Cleaning Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "id": "544091db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313 719\n"
     ]
    }
   ],
   "source": [
    "#AREA\n",
    "nat_count_area = cleaned_data['Area'].isna().sum()\n",
    "num_uniq_area = cleaned_data['Area'].nunique()\n",
    "print(nat_count_area, num_uniq_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "id": "94d8b1b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 ['USA' 'AUSTRALIA' 'MEXICO' 'BRAZIL' 'ENGLAND' 'SOUTH AFRICA' 'THAILAND'\n",
      " 'COSTA RICA' 'MALDIVES' 'BAHAMAS' 'NEW CALEDONIA' 'ECUADOR' 'MALAYSIA'\n",
      " 'LIBYA' nan 'CUBA' 'MAURITIUS' 'NEW ZEALAND' 'SPAIN' 'SAMOA'\n",
      " 'SOLOMON ISLANDS' 'JAPAN' 'EGYPT' 'ST HELENA, British overseas territory'\n",
      " 'COMOROS' 'REUNION' 'FRENCH POLYNESIA' 'UNITED KINGDOM'\n",
      " 'UNITED ARAB EMIRATES' 'PHILIPPINES' 'INDONESIA' 'CHINA' 'COLUMBIA'\n",
      " 'CAPE VERDE' 'Fiji' 'DOMINICAN REPUBLIC' 'CAYMAN ISLANDS' 'ARUBA'\n",
      " 'MOZAMBIQUE' 'FIJI' 'PUERTO RICO' 'ITALY' 'ATLANTIC OCEAN' 'GREECE'\n",
      " 'ST. MARTIN' 'FRANCE' 'PAPUA NEW GUINEA' 'TRINIDAD & TOBAGO' 'KIRIBATI'\n",
      " 'ISRAEL' 'DIEGO GARCIA' 'TAIWAN' 'JAMAICA' 'PALESTINIAN TERRITORIES'\n",
      " 'GUAM' 'SEYCHELLES' 'BELIZE' 'NIGERIA' 'TONGA' 'SCOTLAND' 'CANADA'\n",
      " 'CROATIA' 'SAUDI ARABIA' 'CHILE' 'ANTIGUA' 'KENYA' 'RUSSIA'\n",
      " 'TURKS & CAICOS' 'UNITED ARAB EMIRATES (UAE)' 'AZORES' 'SOUTH KOREA'\n",
      " 'MALTA' 'VIETNAM' 'MADAGASCAR' 'PANAMA' 'SOMALIA' 'NEVIS'\n",
      " 'BRITISH VIRGIN ISLANDS' 'NORWAY' 'SENEGAL' 'YEMEN' 'GULF OF ADEN'\n",
      " 'Sierra Leone' 'ST. MAARTIN' 'GRAND CAYMAN' 'Seychelles' 'LIBERIA'\n",
      " 'VANUATU' 'MEXICO ' 'HONDURAS' 'VENEZUELA' 'SRI LANKA' ' TONGA' 'URUGUAY'\n",
      " 'INDIA' 'MICRONESIA' 'CARIBBEAN SEA' 'OKINAWA' 'TANZANIA'\n",
      " 'MARSHALL ISLANDS' 'EGYPT / ISRAEL' 'NORTHERN ARABIAN SEA' 'HONG KONG'\n",
      " 'EL SALVADOR' 'ANGOLA' 'BERMUDA' 'MONTENEGRO' 'IRAN' 'TUNISIA' 'NAMIBIA'\n",
      " 'NORTH ATLANTIC OCEAN' 'PORTUGAL' 'SOUTH CHINA SEA' 'BANGLADESH' 'PALAU'\n",
      " 'WESTERN SAMOA' 'PACIFIC OCEAN ' 'BRITISH ISLES' 'GRENADA' 'IRAQ'\n",
      " 'TURKEY' 'SINGAPORE' 'NEW BRITAIN' 'SUDAN' 'JOHNSTON ISLAND'\n",
      " 'SOUTH PACIFIC OCEAN' 'NEW GUINEA' 'RED SEA' 'NORTH PACIFIC OCEAN'\n",
      " 'FEDERATED STATES OF MICRONESIA' 'MID ATLANTIC OCEAN' 'ADMIRALTY ISLANDS'\n",
      " 'BRITISH WEST INDIES' 'SOUTH ATLANTIC OCEAN' 'PERSIAN GULF'\n",
      " 'RED SEA / INDIAN OCEAN' 'PACIFIC OCEAN' 'NORTH SEA' 'NICARAGUA '\n",
      " 'MALDIVE ISLANDS' 'AMERICAN SAMOA' 'ANDAMAN / NICOBAR ISLANDAS' 'GABON'\n",
      " 'MAYOTTE' 'NORTH ATLANTIC OCEAN ' 'THE BALKANS' 'SUDAN?' 'ARGENTINA'\n",
      " 'MARTINIQUE' 'INDIAN OCEAN' 'GUATEMALA' 'NETHERLANDS ANTILLES'\n",
      " 'NORTHERN MARIANA ISLANDS' 'IRAN / IRAQ' 'JAVA' 'SIERRA LEONE'\n",
      " ' PHILIPPINES' 'NICARAGUA' 'CENTRAL PACIFIC' 'SOLOMON ISLANDS / VANUATU'\n",
      " 'SOUTHWEST PACIFIC OCEAN' 'BAY OF BENGAL' 'MID-PACIFC OCEAN' 'SLOVENIA'\n",
      " 'CURACAO' 'ICELAND' 'ITALY / CROATIA' 'BARBADOS' 'MONACO' 'GUYANA'\n",
      " 'HAITI' 'SAN DOMINGO' 'IRELAND' 'KUWAIT' 'YEMEN ' 'REUNION ISLAND'\n",
      " 'FALKLAND ISLANDS' 'CRETE' 'CYPRUS'] 178\n"
     ]
    }
   ],
   "source": [
    "#COUNTRY\n",
    "nat_count_country = cleaned_data['Country'].isna().sum()\n",
    "uniq_val_country = cleaned_data['Country'].unique()\n",
    "num_uniq_country = cleaned_data['Country'].nunique()\n",
    "print(nat_count_country, uniq_val_country, num_uniq_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "id": "aa1d2cd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Replace NaN values with 'Unknown'\n",
    "cleaned_data['Country'] = cleaned_data['Country'].fillna('Unknown')\n",
    "\n",
    "# Step 2: Extract everything before \"/\"\n",
    "cleaned_data['Country'] = cleaned_data['Country'].str.split('/').str[0]\n",
    "\n",
    "# Step 3: Trim spaces, remove \"?\", and capitalize\n",
    "cleaned_data['Country'] = cleaned_data['Country'].str.strip().str.replace('?', '').str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "id": "92f768c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['usa', 'australia', 'mexico', 'brazil', 'england', 'south africa',\n",
       "       'thailand', 'costa rica', 'maldives', 'bahamas', 'new caledonia',\n",
       "       'ecuador', 'malaysia', 'libya', 'unknown', 'cuba', 'mauritius',\n",
       "       'new zealand', 'spain', 'samoa', 'solomon islands', 'japan',\n",
       "       'egypt', 'st helena, british overseas territory', 'comoros',\n",
       "       'reunion', 'french polynesia', 'united kingdom',\n",
       "       'united arab emirates', 'philippines', 'indonesia', 'china',\n",
       "       'columbia', 'cape verde', 'fiji', 'dominican republic',\n",
       "       'cayman islands', 'aruba', 'mozambique', 'puerto rico', 'italy',\n",
       "       'atlantic ocean', 'greece', 'st. martin', 'france',\n",
       "       'papua new guinea', 'trinidad & tobago', 'kiribati', 'israel',\n",
       "       'diego garcia', 'taiwan', 'jamaica', 'palestinian territories',\n",
       "       'guam', 'seychelles', 'belize', 'nigeria', 'tonga', 'scotland',\n",
       "       'canada', 'croatia', 'saudi arabia', 'chile', 'antigua', 'kenya',\n",
       "       'russia', 'turks & caicos', 'united arab emirates (uae)', 'azores',\n",
       "       'south korea', 'malta', 'vietnam', 'madagascar', 'panama',\n",
       "       'somalia', 'nevis', 'british virgin islands', 'norway', 'senegal',\n",
       "       'yemen', 'gulf of aden', 'sierra leone', 'st. maartin',\n",
       "       'grand cayman', 'liberia', 'vanuatu', 'honduras', 'venezuela',\n",
       "       'sri lanka', 'uruguay', 'india', 'micronesia', 'caribbean sea',\n",
       "       'okinawa', 'tanzania', 'marshall islands', 'northern arabian sea',\n",
       "       'hong kong', 'el salvador', 'angola', 'bermuda', 'montenegro',\n",
       "       'iran', 'tunisia', 'namibia', 'north atlantic ocean', 'portugal',\n",
       "       'south china sea', 'bangladesh', 'palau', 'western samoa',\n",
       "       'pacific ocean', 'british isles', 'grenada', 'iraq', 'turkey',\n",
       "       'singapore', 'new britain', 'sudan', 'johnston island',\n",
       "       'south pacific ocean', 'new guinea', 'red sea',\n",
       "       'north pacific ocean', 'federated states of micronesia',\n",
       "       'mid atlantic ocean', 'admiralty islands', 'british west indies',\n",
       "       'south atlantic ocean', 'persian gulf', 'north sea', 'nicaragua',\n",
       "       'maldive islands', 'american samoa', 'andaman', 'gabon', 'mayotte',\n",
       "       'the balkans', 'argentina', 'martinique', 'indian ocean',\n",
       "       'guatemala', 'netherlands antilles', 'northern mariana islands',\n",
       "       'java', 'central pacific', 'southwest pacific ocean',\n",
       "       'bay of bengal', 'mid-pacifc ocean', 'slovenia', 'curacao',\n",
       "       'iceland', 'barbados', 'monaco', 'guyana', 'haiti', 'san domingo',\n",
       "       'ireland', 'kuwait', 'reunion island', 'falkland islands', 'crete',\n",
       "       'cyprus'], dtype=object)"
      ]
     },
     "execution_count": 1222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_val_country = cleaned_data['Country'].unique()\n",
    "uniq_val_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "id": "19501c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "import pycountry\n",
    "\n",
    "def match_country(country):\n",
    "    # Get a list of all country names from pycountry\n",
    "    country_names = [c.name for c in pycountry.countries]\n",
    "    \n",
    "    # Find the closest match to the input country name\n",
    "    matched_country = process.extractOne(country, country_names, score_cutoff=80)  # Adjust the score_cutoff as needed\n",
    "    \n",
    "    # Return the matched country name\n",
    "    return matched_country[0] if matched_country else country\n",
    "\n",
    "# Apply the matching function to the 'Country' column\n",
    "cleaned_data['Country'] = cleaned_data['Country'].apply(match_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "id": "5d15afe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Extracted_Month</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal_(Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species_</th>\n",
       "      <th>Investigator_or_Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href_formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Boating</td>\n",
       "      <td>usa</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>18h00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>usa</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>14h00  -15h00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>usa</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6301.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case_Number         Date  Year Extracted_Month        Type Country  \\\n",
       "0  2018.06.25  25-Jun-2018  2018              06     Boating     usa   \n",
       "1  2018.06.18  18-Jun-2018  2018              06  Unprovoked     usa   \n",
       "2  2018.06.09  09-Jun-2018  2018              06     Invalid     usa   \n",
       "\n",
       "         Area                        Location  Activity             Name  ...  \\\n",
       "0  California     Oceanside, San Diego County  Paddling      Julie Wolfe  ...   \n",
       "1     Georgia  St. Simon Island, Glynn County  Standing  Adyson McNeely   ...   \n",
       "2      Hawaii                    Habush, Oahu   Surfing      John Denges  ...   \n",
       "\n",
       "  Age                                             Injury Fatal_(Y/N)  \\\n",
       "0  57  No injury to occupant, outrigger canoe and pad...           N   \n",
       "1  11                         Minor injury to left thigh           N   \n",
       "2  48       Injury to left lower leg from surfboard skeg           N   \n",
       "\n",
       "            Time     Species_          Investigator_or_Source  \\\n",
       "0          18h00  White shark                R. Collier, GSAF   \n",
       "1  14h00  -15h00          NaN  K.McMurray, TrackingSharks.com   \n",
       "2          07h45          NaN  K.McMurray, TrackingSharks.com   \n",
       "\n",
       "                      pdf                                       href_formula  \\\n",
       "0    2018.06.25-Wolfe.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  2018.06.18-McNeely.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2   2018.06.09-Denges.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href original_order  \n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...         6303.0  \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...         6302.0  \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...         6301.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 1224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435026a9",
   "metadata": {},
   "source": [
    "## 2.6 Cleaning Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "id": "f9df7c68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435 ['Paddling' 'Standing' 'Surfing' ... 'Hunting seashells' ' '\n",
      " 'Standing, gathering oysters'] 1325\n"
     ]
    }
   ],
   "source": [
    "#ACTIVITY\n",
    "nat_count_activity = cleaned_data['Activity'].isna().sum()\n",
    "uniq_val_activity = cleaned_data['Activity'].unique()\n",
    "num_uniq_activity = cleaned_data['Activity'].nunique()\n",
    "print(nat_count_activity, uniq_val_activity, num_uniq_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "id": "fc834ed6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>surfing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>surfing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activity\n",
       "0  surfing\n",
       "1  bathing\n",
       "2  surfing"
      ]
     },
     "execution_count": 1226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Fill NaN values\n",
    "cleaned_data['Activity'] = cleaned_data['Activity'].fillna('Unknown')\n",
    "\n",
    "# Step 2: Extract string before \"/\"\n",
    "cleaned_data['Activity'] = cleaned_data['Activity'].apply(lambda x: x.split('/')[0] if isinstance(x, str) else x)\n",
    "\n",
    "# Step 3: Standardize text\n",
    "cleaned_data['Activity'] = cleaned_data['Activity'].str.lower().str.strip()\n",
    "\n",
    "# Step 4: Group activities\n",
    "activity_mapping = {\n",
    "    'surf|boarding|padd': 'surfing',\n",
    "    'swimming': 'swimming',\n",
    "    'fishing': 'fishing',\n",
    "    'diving': 'diving',\n",
    "    'boat|sail': 'sailing',\n",
    "}\n",
    "for key, value in activity_mapping.items():\n",
    "    cleaned_data['Activity'] = np.where(cleaned_data['Activity'].str.contains(key), value, cleaned_data['Activity'])\n",
    "\n",
    "# Step 5: Grouping for bathing-related activities\n",
    "bathing_keywords = ['bathing', 'standing', 'walking', 'wading','splashing','treading water', 'floating','jump', 'dangling','playing']\n",
    "cleaned_data['Activity'] = np.where(cleaned_data['Activity'].str.contains('|'.join(bathing_keywords)), 'bathing', cleaned_data['Activity'])\n",
    "\n",
    "\n",
    "# Displaying a sample of the dataframe to verify the changes\n",
    "cleaned_data[['Activity']].head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "id": "ed7a9682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Activity\n",
       "surfing         1405\n",
       "fishing         1040\n",
       "swimming         946\n",
       "bathing          515\n",
       "diving           457\n",
       "unknown          438\n",
       "snorkeling        88\n",
       "sailing           79\n",
       "kayaking          40\n",
       "sea disaster      13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contar la frecuencia de cada valor en la columna 'Activity'\n",
    "value_counts = cleaned_data['Activity'].value_counts()\n",
    "\n",
    "# Displaying top 10 activities with more attacks\n",
    "top_10_activities = value_counts.head(10)\n",
    "top_10_activities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd48b9a",
   "metadata": {},
   "source": [
    "## 2.7 Cleaning Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "id": "6b7597ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501 ['F' 'M' nan 'M ' 'lli' 'N' '.'] 6\n"
     ]
    }
   ],
   "source": [
    "#SEX\n",
    "nat_count_sex = cleaned_data['Sex_'].isna().sum()\n",
    "uniq_val_sex = cleaned_data['Sex_'].unique()\n",
    "num_uniq_sex = cleaned_data['Sex_'].nunique()\n",
    "print(nat_count_sex, uniq_val_sex, num_uniq_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "id": "e5b77c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Sex_\n",
      "0  Female\n",
      "1  Female\n",
      "2    Male\n",
      "3    Male\n",
      "4    Male\n"
     ]
    }
   ],
   "source": [
    "if cleaned_data['Sex_'].isin(['Female', 'Male', 'Unknown']).all():\n",
    "    print(\"Data has already been cleaned.\")\n",
    "else:\n",
    "    # Step 1: Fill NaN values\n",
    "    cleaned_data['Sex_'] = cleaned_data['Sex_'].fillna('Unknown')\n",
    "\n",
    "    # Step 2: Standardize text\n",
    "    cleaned_data['Sex_'] = cleaned_data['Sex_'].str.lower()\n",
    "\n",
    "    # Step 3: Group values\n",
    "    cleaned_data['Sex_'] = cleaned_data['Sex_'].replace({'f': 'Female', 'm': 'Male'})\n",
    "    cleaned_data['Sex_'] = cleaned_data['Sex_'].apply(lambda x: x if x in ['Female', 'Male'] else 'Unknown')\n",
    "\n",
    "    # Displaying a sample of the dataframe to verify the changes\n",
    "    print(cleaned_data[['Sex_']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28839fd",
   "metadata": {},
   "source": [
    "## 2.8 Cleaning Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "id": "b886f9bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2183 ['57' '11' '48' nan '18' '52' '15' '12' '32' '10' '21' '34' '30' '60' '33'\n",
      " '29' '54' '41' '37' '56' '19' '25' '69' '38' '55' '35' '46' '45' '14'\n",
      " '40s' '28' '20' '24' '26' '49' '22' '7' '31' '17' '40' '13' '42' '3' '8'\n",
      " '50' '16' '82' '73' '20s' '68' '51' '39' '58' 'Teen' '47' '61' '65' '36'\n",
      " '66' '43' '60s' '9' '72' '59' '6' '27' '64' '23' '71' '44' '62' '63' '70'\n",
      " '18 months' '53' '30s' '50s' 'teen' '77' '74' '28 & 26' '5' '86'\n",
      " '18 or 20' '12 or 13' '46 & 34' '28, 23 & 30' 'Teens' '36 & 26' '8 or 10'\n",
      " '84' '\\xa0 ' ' ' '30 or 36' '6½' '21 & ?' '75' '33 or 37' 'mid-30s'\n",
      " '23 & 20' ' 30' '7      &    31' ' 28' '20?' \"60's\" '32 & 30' '16 to 18'\n",
      " '87' '67' 'Elderly' 'mid-20s' 'Ca. 33' '74 ' '45 ' '21 or 26' '20 ' '>50'\n",
      " '18 to 22' 'adult' '9 & 12' '? & 19' '9 months' '25 to 35' '23 & 26' '1'\n",
      " '(adult)' '33 & 37' '25 or 28' '37, 67, 35, 27,  ? & 27' '21, 34,24 & 35'\n",
      " '30 & 32' '50 & 30' '17 & 35' 'X' '\"middle-age\"' '13 or 18' '34 & 19'\n",
      " '33 & 26' '2 to 3 months' 'MAKE LINE GREEN' ' 43' '81' '\"young\"' '7 or 8'\n",
      " '78' '17 & 16' 'F' 'Both 11' '9 or 10' 'young' '36 & 23' '  ' 'A.M.'\n",
      " '?    &   14' '10 or 12' '31 or 33'] 155\n"
     ]
    }
   ],
   "source": [
    "#AGE\n",
    "nat_count_age = cleaned_data['Age'].isna().sum()\n",
    "uniq_val_age = cleaned_data['Age'].unique()\n",
    "num_uniq_age = cleaned_data['Age'].nunique()\n",
    "print(nat_count_age, uniq_val_age, num_uniq_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "id": "a3c22576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['57', '11', '48', 'Invalid', '18', '52', '15', '12', '32', '10',\n",
       "       '21', '34', '30', '60', '33', '29', '54', '41', '37', '56', '19',\n",
       "       '25', '69', '38', '55', '35', '46', '45', '14', '40', '28', '20',\n",
       "       '24', '26', '49', '22', '7', '31', '17', '13', '42', '3', '8',\n",
       "       '50', '16', '82', '73', '68', '51', '39', '58', '47', '61', '65',\n",
       "       '36', '66', '43', '9', '72', '59', '6', '27', '64', '23', '71',\n",
       "       '44', '62', '63', '70', '1', '53', '77', '74', '5', '86', '84',\n",
       "       '75', '87', '67', '81', '78'], dtype=object)"
      ]
     },
     "execution_count": 1231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all spaces (leading, trailing, and in the middle)\n",
    "cleaned_data['Age'] = cleaned_data['Age'].str.replace(' ', '', regex=True)\n",
    "\n",
    "# Replace values with \"month\" to '1'\n",
    "cleaned_data['Age'] = cleaned_data['Age'].replace(r'.*month.*', '1', regex=True)\n",
    "\n",
    "# if there is an s next to a digit then leave the digit\n",
    "cleaned_data['Age'] = cleaned_data['Age'].str.replace(r'(\\d)s', r'\\1', regex=True)\n",
    "\n",
    "# If a value contains \"to\", \"&\", or \"or\", conserve just the first two digits of that value\n",
    "cleaned_data['Age'] = cleaned_data['Age'].str.replace(r'(\\d{1,2})\\s*(to|&|or|,)\\s*\\d+', r'\\1', regex=True)\n",
    "\n",
    "# Fill NaN values in 'Age' column with 'Unknown'\n",
    "cleaned_data['Age'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "# Replace all values that aren't one or two digit numbers with \"Invalid\"\n",
    "cleaned_data['Age'] = cleaned_data['Age'].apply(lambda x: x if x.isdigit() and len(x) <= 2 else 'Invalid')\n",
    "\n",
    "\n",
    "uniq_val_age = cleaned_data['Age'].unique()\n",
    "uniq_val_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "id": "1c717281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    57.0\n",
       "1    11.0\n",
       "2    48.0\n",
       "3     NaN\n",
       "4     NaN\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 1232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'Age' column to integers, replacing \"Invalid\" with pd.NA\n",
    "cleaned_data['Age'] = pd.to_numeric(cleaned_data['Age'], errors='coerce')\n",
    "cleaned_data['Age'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72d688c",
   "metadata": {},
   "source": [
    "## 2.9 Cleaning Fatal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "id": "72adb4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464 ['N' 'Y' nan 'M' 'UNKNOWN' '2017' ' N' 'N '] 7\n"
     ]
    }
   ],
   "source": [
    "#FATAL\n",
    "nat_count_fatal = cleaned_data['Fatal_(Y/N)'].isna().sum()\n",
    "uniq_val_fatal = cleaned_data['Fatal_(Y/N)'].unique()\n",
    "num_uniq_fatal = cleaned_data['Fatal_(Y/N)'].nunique()\n",
    "print(nat_count_fatal, uniq_val_fatal, num_uniq_fatal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "id": "3864b9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no', 'yes', 'Unknown'], dtype=object)"
      ]
     },
     "execution_count": 1235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Remove all spaces and convert to lowercase\n",
    "cleaned_data['Fatal_(Y/N)'] = cleaned_data['Fatal_(Y/N)'].str.replace(' ', '').str.lower()\n",
    "\n",
    "# 2) Replace specific unwanted values with NaN\n",
    "cleaned_data['Fatal_(Y/N)'].replace({'m': np.nan, 'unknown': np.nan, '2017': np.nan}, inplace=True)\n",
    "\n",
    "# 3) Group all \"n\" under \"No\", all \"y\" under \"Yes\", and the rest under \"Unknown\"\n",
    "cleaned_data['Fatal_(Y/N)'] = cleaned_data['Fatal_(Y/N)'].replace({'n': 'No', 'y': 'Yes'}).fillna('Unknown')\n",
    "\n",
    "# Display unique values in the 'Fatal (Y/N)' column after transformation\n",
    "cleaned_data['Fatal_(Y/N)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "id": "4aaf9695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your clean data is in a DataFrame named 'cleaned_data'\n",
    "# Specify the file path where you want to save the CSV file\n",
    "csv_file_path = \"/Users/mairagutierrez/Documents/Ironhack/PROJECTS/project--I/src/cleaning.ipynb\"\n",
    "\n",
    "# Export the clean data to a CSV file\n",
    "cleaned_data.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd187f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
