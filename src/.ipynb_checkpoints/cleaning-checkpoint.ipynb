{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e63b08c5",
   "metadata": {},
   "source": [
    "# 2. Cleaning the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67180b8",
   "metadata": {},
   "source": [
    "## 2.1 Preliminar Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1372,
   "id": "5156d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from fuzzywuzzy import process\n",
    "import pycountry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1373,
   "id": "7fd8b14a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case Number         Date    Year        Type Country        Area  \\\n",
       "0  2018.06.25  25-Jun-2018  2018.0     Boating     USA  California   \n",
       "1  2018.06.18  18-Jun-2018  2018.0  Unprovoked     USA     Georgia   \n",
       "2  2018.06.09  09-Jun-2018  2018.0     Invalid     USA      Hawaii   \n",
       "\n",
       "                         Location  Activity             Name Sex   ...  \\\n",
       "0     Oceanside, San Diego County  Paddling      Julie Wolfe    F  ...   \n",
       "1  St. Simon Island, Glynn County  Standing  Adyson McNeely     F  ...   \n",
       "2                    Habush, Oahu   Surfing      John Denges    M  ...   \n",
       "\n",
       "      Species           Investigator or Source                     pdf  \\\n",
       "0  White shark                R. Collier, GSAF    2018.06.25-Wolfe.pdf   \n",
       "1          NaN  K.McMurray, TrackingSharks.com  2018.06.18-McNeely.pdf   \n",
       "2          NaN  K.McMurray, TrackingSharks.com   2018.06.09-Denges.pdf   \n",
       "\n",
       "                                        href formula  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href Case Number.1  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.25   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.18   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.09   \n",
       "\n",
       "  Case Number.2 original order Unnamed: 22 Unnamed: 23  \n",
       "0    2018.06.25         6303.0         NaN         NaN  \n",
       "1    2018.06.18         6302.0         NaN         NaN  \n",
       "2    2018.06.09         6301.0         NaN         NaN  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 1373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data():\n",
    "    \n",
    "    #Importing CSV\n",
    "    file_path = '/Users/mairagutierrez/Documents/Ironhack/PROJECTS/project--I/data/attacks.csv'\n",
    "    \n",
    "    # Try reading the file with a different encoding\n",
    "    data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "    return data\n",
    "    \n",
    "data = get_data()\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1374,
   "id": "785aeef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex_</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal_(Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species_</th>\n",
       "      <th>Investigator_or_Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href_formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>18h00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>14h00  -15h00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>48</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6301.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case_Number         Date    Year        Type Country        Area  \\\n",
       "0  2018.06.25  25-Jun-2018  2018.0     Boating     USA  California   \n",
       "1  2018.06.18  18-Jun-2018  2018.0  Unprovoked     USA     Georgia   \n",
       "2  2018.06.09  09-Jun-2018  2018.0     Invalid     USA      Hawaii   \n",
       "\n",
       "                         Location  Activity             Name Sex_ Age  \\\n",
       "0     Oceanside, San Diego County  Paddling      Julie Wolfe    F  57   \n",
       "1  St. Simon Island, Glynn County  Standing  Adyson McNeely     F  11   \n",
       "2                    Habush, Oahu   Surfing      John Denges    M  48   \n",
       "\n",
       "                                              Injury Fatal_(Y/N)  \\\n",
       "0  No injury to occupant, outrigger canoe and pad...           N   \n",
       "1                         Minor injury to left thigh           N   \n",
       "2       Injury to left lower leg from surfboard skeg           N   \n",
       "\n",
       "            Time     Species_          Investigator_or_Source  \\\n",
       "0          18h00  White shark                R. Collier, GSAF   \n",
       "1  14h00  -15h00          NaN  K.McMurray, TrackingSharks.com   \n",
       "2          07h45          NaN  K.McMurray, TrackingSharks.com   \n",
       "\n",
       "                      pdf                                       href_formula  \\\n",
       "0    2018.06.25-Wolfe.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  2018.06.18-McNeely.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2   2018.06.09-Denges.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href  original_order  \n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...          6303.0  \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...          6302.0  \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...          6301.0  "
      ]
     },
     "execution_count": 1374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pre_cleaning(data):\n",
    "    \n",
    "    #dropping columns with 99% missing values and the ones that aren't relevant for my research\n",
    "    pre_cleaned_data = data.drop(columns = ['Unnamed: 22', 'Unnamed: 23', 'Case Number.1', 'Case Number.2'], axis = 1)\n",
    "    \n",
    "    #dropping all rows with NaN in every column\n",
    "    pre_cleaned_data = pre_cleaned_data.dropna(how=\"all\")\n",
    "    \n",
    "    #Remove spaces in column titles\n",
    "    pre_cleaned_data.columns = pre_cleaned_data.columns.str.replace(' ','_')\n",
    "    \n",
    "    return pre_cleaned_data\n",
    "\n",
    "pre_cleaned_data = pre_cleaning(data)\n",
    "pre_cleaned_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1375,
   "id": "a0179e1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case_Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex_', 'Age', 'Injury', 'Fatal_(Y/N)', 'Time',\n",
       "       'Species_', 'Investigator_or_Source', 'pdf', 'href_formula', 'href',\n",
       "       'original_order'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#New data columns names without spaces\n",
    "pre_cleaned_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "id": "9b4ae96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66f8eb",
   "metadata": {},
   "source": [
    "## 2.2 Cleaning Year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "id": "8b1b775b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19423"
      ]
     },
     "execution_count": 1377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_values_count = cleaned_data['Year'].isnull().sum()\n",
    "null_values_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "id": "19b2b41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex_</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal_(Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species_</th>\n",
       "      <th>Investigator_or_Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href_formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>18h00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>14h00  -15h00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>48</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6301.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case_Number         Date  Year        Type Country        Area  \\\n",
       "0  2018.06.25  25-Jun-2018  2018     Boating     USA  California   \n",
       "1  2018.06.18  18-Jun-2018  2018  Unprovoked     USA     Georgia   \n",
       "2  2018.06.09  09-Jun-2018  2018     Invalid     USA      Hawaii   \n",
       "\n",
       "                         Location  Activity             Name Sex_ Age  \\\n",
       "0     Oceanside, San Diego County  Paddling      Julie Wolfe    F  57   \n",
       "1  St. Simon Island, Glynn County  Standing  Adyson McNeely     F  11   \n",
       "2                    Habush, Oahu   Surfing      John Denges    M  48   \n",
       "\n",
       "                                              Injury Fatal_(Y/N)  \\\n",
       "0  No injury to occupant, outrigger canoe and pad...           N   \n",
       "1                         Minor injury to left thigh           N   \n",
       "2       Injury to left lower leg from surfboard skeg           N   \n",
       "\n",
       "            Time     Species_          Investigator_or_Source  \\\n",
       "0          18h00  White shark                R. Collier, GSAF   \n",
       "1  14h00  -15h00          NaN  K.McMurray, TrackingSharks.com   \n",
       "2          07h45          NaN  K.McMurray, TrackingSharks.com   \n",
       "\n",
       "                      pdf                                       href_formula  \\\n",
       "0    2018.06.25-Wolfe.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  2018.06.18-McNeely.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2   2018.06.09-Denges.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href  original_order  \n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...          6303.0  \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...          6302.0  \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...          6301.0  "
      ]
     },
     "execution_count": 1378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Casting Year data type from float to integer\n",
    "pre_cleaned_data['Year'] = pre_cleaned_data['Year'].fillna(0).astype(int) \n",
    "cleaned_data = pre_cleaned_data\n",
    "\n",
    "# Filter dataframe with data over 1900 as this is data relevant to my research\n",
    "cleaned_data = pre_cleaned_data[(cleaned_data['Year'] >= 1900) & (cleaned_data['Year']<= 2018) ]\n",
    "cleaned_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8265555b",
   "metadata": {},
   "source": [
    "## 2.3 Cleaning Case Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "id": "bae9861a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Extracted_Month</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal_(Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species_</th>\n",
       "      <th>Investigator_or_Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href_formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>18h00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>14h00  -15h00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6301.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case_Number         Date  Year Extracted_Month        Type Country  \\\n",
       "0  2018.06.25  25-Jun-2018  2018              06     Boating     USA   \n",
       "1  2018.06.18  18-Jun-2018  2018              06  Unprovoked     USA   \n",
       "2  2018.06.09  09-Jun-2018  2018              06     Invalid     USA   \n",
       "\n",
       "         Area                        Location  Activity             Name  ...  \\\n",
       "0  California     Oceanside, San Diego County  Paddling      Julie Wolfe  ...   \n",
       "1     Georgia  St. Simon Island, Glynn County  Standing  Adyson McNeely   ...   \n",
       "2      Hawaii                    Habush, Oahu   Surfing      John Denges  ...   \n",
       "\n",
       "  Age                                             Injury Fatal_(Y/N)  \\\n",
       "0  57  No injury to occupant, outrigger canoe and pad...           N   \n",
       "1  11                         Minor injury to left thigh           N   \n",
       "2  48       Injury to left lower leg from surfboard skeg           N   \n",
       "\n",
       "            Time     Species_          Investigator_or_Source  \\\n",
       "0          18h00  White shark                R. Collier, GSAF   \n",
       "1  14h00  -15h00          NaN  K.McMurray, TrackingSharks.com   \n",
       "2          07h45          NaN  K.McMurray, TrackingSharks.com   \n",
       "\n",
       "                      pdf                                       href_formula  \\\n",
       "0    2018.06.25-Wolfe.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  2018.06.18-McNeely.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2   2018.06.09-Denges.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href original_order  \n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...         6303.0  \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...         6302.0  \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...         6301.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 1380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing any letter at the end of the date and any spaces.\n",
    "cleaned_data['Case_Number'] = cleaned_data['Case_Number'].str.strip().str.replace(r'[A-Za-z]$', '', regex=True)\n",
    "\n",
    "# Extracting the year from the 'Case_Number' column and creating a new column 'Extracted_Year'\n",
    "#cleaned_data = cleaned_data.assign(Extracted_Year=cleaned_data['Case_Number'].str[:4])\n",
    "\n",
    "# Extracting the month from the 'Case_Number' column\n",
    "cleaned_data = cleaned_data.assign(Extracted_Month=cleaned_data['Case_Number'].str.extract(r'\\.(\\d{2})\\.'))\n",
    "\n",
    "\n",
    "# Reordering columns \n",
    "cleaned_data = cleaned_data[['Case_Number','Date', 'Year','Extracted_Month','Type', 'Country', 'Area', 'Location',\n",
    "       'Activity', 'Name', 'Sex_', 'Age', 'Injury', 'Fatal_(Y/N)', 'Time','Species_', 'Investigator_or_Source', 'pdf', 'href_formula', 'href','original_order']]\n",
    "\n",
    "cleaned_data.head(3)                                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ea6c16",
   "metadata": {},
   "source": [
    "## 2.4 Cleaning Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "id": "1436ab8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 ['Boating' 'Unprovoked' 'Invalid' 'Provoked' 'Questionable' 'Sea Disaster'\n",
      " nan 'Boat' 'Boatomg'] 8\n"
     ]
    }
   ],
   "source": [
    "#TYPE\n",
    "null_values_type = cleaned_data['Type'].isnull().sum()\n",
    "nat_count_type = cleaned_data['Type'].isna().sum()\n",
    "uniq_val_type = cleaned_data['Type'].unique()\n",
    "num_uniq_type = cleaned_data['Type'].nunique()\n",
    "print(null_values_type, nat_count_type, uniq_val_type, num_uniq_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "id": "7551b174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Extracted_Month</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal_(Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species_</th>\n",
       "      <th>Investigator_or_Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href_formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>18h00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>14h00  -15h00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6301.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case_Number         Date  Year Extracted_Month        Type Country  \\\n",
       "0  2018.06.25  25-Jun-2018  2018              06     Boating     USA   \n",
       "1  2018.06.18  18-Jun-2018  2018              06  Unprovoked     USA   \n",
       "2  2018.06.09  09-Jun-2018  2018              06     Invalid     USA   \n",
       "\n",
       "         Area                        Location  Activity             Name  ...  \\\n",
       "0  California     Oceanside, San Diego County  Paddling      Julie Wolfe  ...   \n",
       "1     Georgia  St. Simon Island, Glynn County  Standing  Adyson McNeely   ...   \n",
       "2      Hawaii                    Habush, Oahu   Surfing      John Denges  ...   \n",
       "\n",
       "  Age                                             Injury Fatal_(Y/N)  \\\n",
       "0  57  No injury to occupant, outrigger canoe and pad...           N   \n",
       "1  11                         Minor injury to left thigh           N   \n",
       "2  48       Injury to left lower leg from surfboard skeg           N   \n",
       "\n",
       "            Time     Species_          Investigator_or_Source  \\\n",
       "0          18h00  White shark                R. Collier, GSAF   \n",
       "1  14h00  -15h00          NaN  K.McMurray, TrackingSharks.com   \n",
       "2          07h45          NaN  K.McMurray, TrackingSharks.com   \n",
       "\n",
       "                      pdf                                       href_formula  \\\n",
       "0    2018.06.25-Wolfe.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  2018.06.18-McNeely.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2   2018.06.09-Denges.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href original_order  \n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...         6303.0  \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...         6302.0  \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...         6301.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 1382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Removing spaces at the beginning and the end of the word\n",
    "cleaned_data['Type'] = cleaned_data['Type'].str.strip()\n",
    "\n",
    "# 2) Replacing null values with most common values\n",
    "most_common_value = cleaned_data['Type'].mode()[0]\n",
    "cleaned_data['Type'] = cleaned_data['Type'].fillna(most_common_value)\n",
    "\n",
    "# 3) Converting all values to lower case\n",
    "cleaned_data['Type'] = cleaned_data['Type'].str.lower()\n",
    "\n",
    "# 4) Grouping the values by specified categories\n",
    "cleaned_data['Type'] = cleaned_data['Type'].replace({\n",
    "    r'.*boat.*': 'boating',  # Including all values that have \"boat\" anywhere in the string\n",
    "    'invalid': 'invalid',\n",
    "    'provoked': 'provoked',\n",
    "    'questionable': 'invalid',\n",
    "    'unprovoked': 'unprovoked',\n",
    "    'sea disaster': 'sea disaster'\n",
    "}, regex=True)\n",
    "\n",
    "cleaned_data['Type'] = cleaned_data['Type'].str.capitalize()\n",
    "cleaned_data.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f7f2b9",
   "metadata": {},
   "source": [
    "## 2.5 Cleaning Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "id": "544091db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 313 719\n"
     ]
    }
   ],
   "source": [
    "#AREA\n",
    "null_values_country = cleaned_data['Type'].isnull().sum()\n",
    "nat_count_area = cleaned_data['Area'].isna().sum()\n",
    "num_uniq_area = cleaned_data['Area'].nunique()\n",
    "print(null_values_country, nat_count_area, num_uniq_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "id": "94d8b1b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 ['USA' 'AUSTRALIA' 'MEXICO' 'BRAZIL' 'ENGLAND' 'SOUTH AFRICA' 'THAILAND'\n",
      " 'COSTA RICA' 'MALDIVES' 'BAHAMAS' 'NEW CALEDONIA' 'ECUADOR' 'MALAYSIA'\n",
      " 'LIBYA' nan 'CUBA' 'MAURITIUS' 'NEW ZEALAND' 'SPAIN' 'SAMOA'\n",
      " 'SOLOMON ISLANDS' 'JAPAN' 'EGYPT' 'ST HELENA, British overseas territory'\n",
      " 'COMOROS' 'REUNION' 'FRENCH POLYNESIA' 'UNITED KINGDOM'\n",
      " 'UNITED ARAB EMIRATES' 'PHILIPPINES' 'INDONESIA' 'CHINA' 'COLUMBIA'\n",
      " 'CAPE VERDE' 'Fiji' 'DOMINICAN REPUBLIC' 'CAYMAN ISLANDS' 'ARUBA'\n",
      " 'MOZAMBIQUE' 'FIJI' 'PUERTO RICO' 'ITALY' 'ATLANTIC OCEAN' 'GREECE'\n",
      " 'ST. MARTIN' 'FRANCE' 'PAPUA NEW GUINEA' 'TRINIDAD & TOBAGO' 'KIRIBATI'\n",
      " 'ISRAEL' 'DIEGO GARCIA' 'TAIWAN' 'JAMAICA' 'PALESTINIAN TERRITORIES'\n",
      " 'GUAM' 'SEYCHELLES' 'BELIZE' 'NIGERIA' 'TONGA' 'SCOTLAND' 'CANADA'\n",
      " 'CROATIA' 'SAUDI ARABIA' 'CHILE' 'ANTIGUA' 'KENYA' 'RUSSIA'\n",
      " 'TURKS & CAICOS' 'UNITED ARAB EMIRATES (UAE)' 'AZORES' 'SOUTH KOREA'\n",
      " 'MALTA' 'VIETNAM' 'MADAGASCAR' 'PANAMA' 'SOMALIA' 'NEVIS'\n",
      " 'BRITISH VIRGIN ISLANDS' 'NORWAY' 'SENEGAL' 'YEMEN' 'GULF OF ADEN'\n",
      " 'Sierra Leone' 'ST. MAARTIN' 'GRAND CAYMAN' 'Seychelles' 'LIBERIA'\n",
      " 'VANUATU' 'MEXICO ' 'HONDURAS' 'VENEZUELA' 'SRI LANKA' ' TONGA' 'URUGUAY'\n",
      " 'INDIA' 'MICRONESIA' 'CARIBBEAN SEA' 'OKINAWA' 'TANZANIA'\n",
      " 'MARSHALL ISLANDS' 'EGYPT / ISRAEL' 'NORTHERN ARABIAN SEA' 'HONG KONG'\n",
      " 'EL SALVADOR' 'ANGOLA' 'BERMUDA' 'MONTENEGRO' 'IRAN' 'TUNISIA' 'NAMIBIA'\n",
      " 'NORTH ATLANTIC OCEAN' 'PORTUGAL' 'SOUTH CHINA SEA' 'BANGLADESH' 'PALAU'\n",
      " 'WESTERN SAMOA' 'PACIFIC OCEAN ' 'BRITISH ISLES' 'GRENADA' 'IRAQ'\n",
      " 'TURKEY' 'SINGAPORE' 'NEW BRITAIN' 'SUDAN' 'JOHNSTON ISLAND'\n",
      " 'SOUTH PACIFIC OCEAN' 'NEW GUINEA' 'RED SEA' 'NORTH PACIFIC OCEAN'\n",
      " 'FEDERATED STATES OF MICRONESIA' 'MID ATLANTIC OCEAN' 'ADMIRALTY ISLANDS'\n",
      " 'BRITISH WEST INDIES' 'SOUTH ATLANTIC OCEAN' 'PERSIAN GULF'\n",
      " 'RED SEA / INDIAN OCEAN' 'PACIFIC OCEAN' 'NORTH SEA' 'NICARAGUA '\n",
      " 'MALDIVE ISLANDS' 'AMERICAN SAMOA' 'ANDAMAN / NICOBAR ISLANDAS' 'GABON'\n",
      " 'MAYOTTE' 'NORTH ATLANTIC OCEAN ' 'THE BALKANS' 'SUDAN?' 'ARGENTINA'\n",
      " 'MARTINIQUE' 'INDIAN OCEAN' 'GUATEMALA' 'NETHERLANDS ANTILLES'\n",
      " 'NORTHERN MARIANA ISLANDS' 'IRAN / IRAQ' 'JAVA' 'SIERRA LEONE'\n",
      " ' PHILIPPINES' 'NICARAGUA' 'CENTRAL PACIFIC' 'SOLOMON ISLANDS / VANUATU'\n",
      " 'SOUTHWEST PACIFIC OCEAN' 'BAY OF BENGAL' 'MID-PACIFC OCEAN' 'SLOVENIA'\n",
      " 'CURACAO' 'ICELAND' 'ITALY / CROATIA' 'BARBADOS' 'MONACO' 'GUYANA'\n",
      " 'HAITI' 'SAN DOMINGO' 'IRELAND' 'KUWAIT' 'YEMEN ' 'REUNION ISLAND'\n",
      " 'FALKLAND ISLANDS' 'CRETE' 'CYPRUS'] 178\n"
     ]
    }
   ],
   "source": [
    "#COUNTRY\n",
    "nat_count_country = cleaned_data['Country'].isna().sum()\n",
    "uniq_val_country = cleaned_data['Country'].unique()\n",
    "num_uniq_country = cleaned_data['Country'].nunique()\n",
    "print(nat_count_country, uniq_val_country, num_uniq_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "id": "aa1d2cd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Replace NaN values with 'Unknown'\n",
    "cleaned_data['Country'] = cleaned_data['Country'].fillna('Unknown')\n",
    "\n",
    "# Step 2: Extract everything before \"/\"\n",
    "cleaned_data['Country'] = cleaned_data['Country'].str.split('/').str[0]\n",
    "\n",
    "# Step 3: Trim spaces, remove \"?\", and capitalize\n",
    "cleaned_data['Country'] = cleaned_data['Country'].str.strip().str.replace('?', '').str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "id": "b0e530dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['usa', 'australia', 'mexico', 'brazil', 'england', 'south africa',\n",
       "       'thailand', 'costa rica', 'maldives', 'bahamas', 'new caledonia',\n",
       "       'ecuador', 'malaysia', 'libya', 'unknown', 'cuba', 'mauritius',\n",
       "       'new zealand', 'spain', 'samoa', 'solomon islands', 'japan',\n",
       "       'egypt', 'st helena, british overseas territory', 'comoros',\n",
       "       'reunion', 'french polynesia', 'united kingdom',\n",
       "       'united arab emirates', 'philippines', 'indonesia', 'china',\n",
       "       'columbia', 'cape verde', 'fiji', 'dominican republic',\n",
       "       'cayman islands', 'aruba', 'mozambique', 'puerto rico', 'italy',\n",
       "       'atlantic ocean', 'greece', 'st. martin', 'france',\n",
       "       'papua new guinea', 'trinidad & tobago', 'kiribati', 'israel',\n",
       "       'diego garcia', 'taiwan', 'jamaica', 'palestinian territories',\n",
       "       'guam', 'seychelles', 'belize', 'nigeria', 'tonga', 'scotland',\n",
       "       'canada', 'croatia', 'saudi arabia', 'chile', 'antigua', 'kenya',\n",
       "       'russia', 'turks & caicos', 'united arab emirates (uae)', 'azores',\n",
       "       'south korea', 'malta', 'vietnam', 'madagascar', 'panama',\n",
       "       'somalia', 'nevis', 'british virgin islands', 'norway', 'senegal',\n",
       "       'yemen', 'gulf of aden', 'sierra leone', 'st. maartin',\n",
       "       'grand cayman', 'liberia', 'vanuatu', 'honduras', 'venezuela',\n",
       "       'sri lanka', 'uruguay', 'india', 'micronesia', 'caribbean sea',\n",
       "       'okinawa', 'tanzania', 'marshall islands', 'northern arabian sea',\n",
       "       'hong kong', 'el salvador', 'angola', 'bermuda', 'montenegro',\n",
       "       'iran', 'tunisia', 'namibia', 'north atlantic ocean', 'portugal',\n",
       "       'south china sea', 'bangladesh', 'palau', 'western samoa',\n",
       "       'pacific ocean', 'british isles', 'grenada', 'iraq', 'turkey',\n",
       "       'singapore', 'new britain', 'sudan', 'johnston island',\n",
       "       'south pacific ocean', 'new guinea', 'red sea',\n",
       "       'north pacific ocean', 'federated states of micronesia',\n",
       "       'mid atlantic ocean', 'admiralty islands', 'british west indies',\n",
       "       'south atlantic ocean', 'persian gulf', 'north sea', 'nicaragua',\n",
       "       'maldive islands', 'american samoa', 'andaman', 'gabon', 'mayotte',\n",
       "       'the balkans', 'argentina', 'martinique', 'indian ocean',\n",
       "       'guatemala', 'netherlands antilles', 'northern mariana islands',\n",
       "       'java', 'central pacific', 'southwest pacific ocean',\n",
       "       'bay of bengal', 'mid-pacifc ocean', 'slovenia', 'curacao',\n",
       "       'iceland', 'barbados', 'monaco', 'guyana', 'haiti', 'san domingo',\n",
       "       'ireland', 'kuwait', 'reunion island', 'falkland islands', 'crete',\n",
       "       'cyprus'], dtype=object)"
      ]
     },
     "execution_count": 1386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_val_country = cleaned_data['Country'].unique()\n",
    "uniq_val_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "id": "19501c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "import pycountry\n",
    "\n",
    "def match_country(country):\n",
    "    # Get a list of all country names from pycountry\n",
    "    country_names = [c.name for c in pycountry.countries]\n",
    "    \n",
    "    # Find the closest match to the input country name\n",
    "    matched_country = process.extractOne(country, country_names, score_cutoff=80)  # Adjust the score_cutoff as needed\n",
    "    \n",
    "    # Return the matched country name\n",
    "    return matched_country[0] if matched_country else country\n",
    "\n",
    "# Apply the matching function to the 'Country' column\n",
    "cleaned_data['Country'] = cleaned_data['Country'].apply(match_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "id": "cb5188c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Extracted_Month</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal_(Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species_</th>\n",
       "      <th>Investigator_or_Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href_formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Boating</td>\n",
       "      <td>usa</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>18h00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>usa</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>14h00  -15h00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>usa</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6301.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case_Number         Date  Year Extracted_Month        Type Country  \\\n",
       "0  2018.06.25  25-Jun-2018  2018              06     Boating     usa   \n",
       "1  2018.06.18  18-Jun-2018  2018              06  Unprovoked     usa   \n",
       "2  2018.06.09  09-Jun-2018  2018              06     Invalid     usa   \n",
       "\n",
       "         Area                        Location  Activity             Name  ...  \\\n",
       "0  California     Oceanside, San Diego County  Paddling      Julie Wolfe  ...   \n",
       "1     Georgia  St. Simon Island, Glynn County  Standing  Adyson McNeely   ...   \n",
       "2      Hawaii                    Habush, Oahu   Surfing      John Denges  ...   \n",
       "\n",
       "  Age                                             Injury Fatal_(Y/N)  \\\n",
       "0  57  No injury to occupant, outrigger canoe and pad...           N   \n",
       "1  11                         Minor injury to left thigh           N   \n",
       "2  48       Injury to left lower leg from surfboard skeg           N   \n",
       "\n",
       "            Time     Species_          Investigator_or_Source  \\\n",
       "0          18h00  White shark                R. Collier, GSAF   \n",
       "1  14h00  -15h00          NaN  K.McMurray, TrackingSharks.com   \n",
       "2          07h45          NaN  K.McMurray, TrackingSharks.com   \n",
       "\n",
       "                      pdf                                       href_formula  \\\n",
       "0    2018.06.25-Wolfe.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  2018.06.18-McNeely.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2   2018.06.09-Denges.pdf  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href original_order  \n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...         6303.0  \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...         6302.0  \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...         6301.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 1388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5853a44",
   "metadata": {},
   "source": [
    "## 2.6 Cleaning Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "id": "f9df7c68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435 ['Paddling' 'Standing' 'Surfing' ... 'Hunting seashells' ' '\n",
      " 'Standing, gathering oysters'] 1325\n"
     ]
    }
   ],
   "source": [
    "#ACTIVITY\n",
    "nat_count_activity = cleaned_data['Activity'].isna().sum()\n",
    "uniq_val_activity = cleaned_data['Activity'].unique()\n",
    "num_uniq_activity = cleaned_data['Activity'].nunique()\n",
    "print(nat_count_activity, uniq_val_activity, num_uniq_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "id": "8e1e5ed0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>surfing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>surfing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activity\n",
       "0  surfing\n",
       "1  bathing\n",
       "2  surfing"
      ]
     },
     "execution_count": 1390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Fill NaN values\n",
    "cleaned_data['Activity'] = cleaned_data['Activity'].fillna('Unknown')\n",
    "\n",
    "# Step 2: Extract string before \"/\"\n",
    "cleaned_data['Activity'] = cleaned_data['Activity'].apply(lambda x: x.split('/')[0] if isinstance(x, str) else x)\n",
    "\n",
    "# Step 3: Standardize text\n",
    "cleaned_data['Activity'] = cleaned_data['Activity'].str.lower().str.strip()\n",
    "\n",
    "# Step 4: Group activities\n",
    "activity_mapping = {\n",
    "    'surf|boarding|padd': 'surfing',\n",
    "    'swimming': 'swimming',\n",
    "    'fishing': 'fishing',\n",
    "    'diving': 'diving',\n",
    "    'boat|sail': 'sailing',\n",
    "}\n",
    "for key, value in activity_mapping.items():\n",
    "    cleaned_data['Activity'] = np.where(cleaned_data['Activity'].str.contains(key), value, cleaned_data['Activity'])\n",
    "\n",
    "# Step 5: Grouping for bathing-related activities\n",
    "bathing_keywords = ['bathing', 'standing', 'walking', 'wading','splashing','treading water', 'floating','jump', 'dangling','playing']\n",
    "cleaned_data['Activity'] = np.where(cleaned_data['Activity'].str.contains('|'.join(bathing_keywords)), 'bathing', cleaned_data['Activity'])\n",
    "\n",
    "\n",
    "# Displaying a sample of the dataframe to verify the changes\n",
    "cleaned_data[['Activity']].head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "id": "0b4c8fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Activity\n",
       "surfing         1405\n",
       "fishing         1040\n",
       "swimming         946\n",
       "bathing          515\n",
       "diving           457\n",
       "unknown          438\n",
       "snorkeling        88\n",
       "sailing           79\n",
       "kayaking          40\n",
       "sea disaster      13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contar la frecuencia de cada valor en la columna 'Activity'\n",
    "value_counts = cleaned_data['Activity'].value_counts()\n",
    "\n",
    "# Displaying top 10 activities with more attacks\n",
    "top_10_activities = value_counts.head(10)\n",
    "top_10_activities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff0d506",
   "metadata": {},
   "source": [
    "## 2.7 Cleaning Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "id": "6b7597ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501 ['F' 'M' nan 'M ' 'lli' 'N' '.'] 6\n"
     ]
    }
   ],
   "source": [
    "#SEX\n",
    "nat_count_sex = cleaned_data['Sex_'].isna().sum()\n",
    "uniq_val_sex = cleaned_data['Sex_'].unique()\n",
    "num_uniq_sex = cleaned_data['Sex_'].nunique()\n",
    "print(nat_count_sex, uniq_val_sex, num_uniq_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "id": "04d61533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Sex_\n",
      "0  Female\n",
      "1  Female\n",
      "2    Male\n",
      "3    Male\n",
      "4    Male\n"
     ]
    }
   ],
   "source": [
    "if cleaned_data['Sex_'].isin(['Female', 'Male', 'Unknown']).all():\n",
    "    print(\"Data has already been cleaned.\")\n",
    "else:\n",
    "    # Step 1: Fill NaN values\n",
    "    cleaned_data['Sex_'] = cleaned_data['Sex_'].fillna('Unknown')\n",
    "\n",
    "    # Step 2: Standardize text\n",
    "    cleaned_data['Sex_'] = cleaned_data['Sex_'].str.lower()\n",
    "\n",
    "    # Step 3: Group values\n",
    "    cleaned_data['Sex_'] = cleaned_data['Sex_'].replace({'f': 'Female', 'm': 'Male'})\n",
    "    cleaned_data['Sex_'] = cleaned_data['Sex_'].apply(lambda x: x if x in ['Female', 'Male'] else 'Unknown')\n",
    "\n",
    "    # Displaying a sample of the dataframe to verify the changes\n",
    "    print(cleaned_data[['Sex_']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebeba32",
   "metadata": {},
   "source": [
    "## 2.8 Cleaning Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "id": "b886f9bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2183 ['57' '11' '48' nan '18' '52' '15' '12' '32' '10' '21' '34' '30' '60' '33'\n",
      " '29' '54' '41' '37' '56' '19' '25' '69' '38' '55' '35' '46' '45' '14'\n",
      " '40s' '28' '20' '24' '26' '49' '22' '7' '31' '17' '40' '13' '42' '3' '8'\n",
      " '50' '16' '82' '73' '20s' '68' '51' '39' '58' 'Teen' '47' '61' '65' '36'\n",
      " '66' '43' '60s' '9' '72' '59' '6' '27' '64' '23' '71' '44' '62' '63' '70'\n",
      " '18 months' '53' '30s' '50s' 'teen' '77' '74' '28 & 26' '5' '86'\n",
      " '18 or 20' '12 or 13' '46 & 34' '28, 23 & 30' 'Teens' '36 & 26' '8 or 10'\n",
      " '84' '\\xa0 ' ' ' '30 or 36' '6½' '21 & ?' '75' '33 or 37' 'mid-30s'\n",
      " '23 & 20' ' 30' '7      &    31' ' 28' '20?' \"60's\" '32 & 30' '16 to 18'\n",
      " '87' '67' 'Elderly' 'mid-20s' 'Ca. 33' '74 ' '45 ' '21 or 26' '20 ' '>50'\n",
      " '18 to 22' 'adult' '9 & 12' '? & 19' '9 months' '25 to 35' '23 & 26' '1'\n",
      " '(adult)' '33 & 37' '25 or 28' '37, 67, 35, 27,  ? & 27' '21, 34,24 & 35'\n",
      " '30 & 32' '50 & 30' '17 & 35' 'X' '\"middle-age\"' '13 or 18' '34 & 19'\n",
      " '33 & 26' '2 to 3 months' 'MAKE LINE GREEN' ' 43' '81' '\"young\"' '7 or 8'\n",
      " '78' '17 & 16' 'F' 'Both 11' '9 or 10' 'young' '36 & 23' '  ' 'A.M.'\n",
      " '?    &   14' '10 or 12' '31 or 33'] 155\n"
     ]
    }
   ],
   "source": [
    "#AGE\n",
    "nat_count_age = cleaned_data['Age'].isna().sum()\n",
    "uniq_val_age = cleaned_data['Age'].unique()\n",
    "num_uniq_age = cleaned_data['Age'].nunique()\n",
    "print(nat_count_age, uniq_val_age, num_uniq_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "id": "623c3540",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['57', '11', '48', 'Invalid', '18', '52', '15', '12', '32', '10',\n",
       "       '21', '34', '30', '60', '33', '29', '54', '41', '37', '56', '19',\n",
       "       '25', '69', '38', '55', '35', '46', '45', '14', '40', '28', '20',\n",
       "       '24', '26', '49', '22', '7', '31', '17', '13', '42', '3', '8',\n",
       "       '50', '16', '82', '73', '68', '51', '39', '58', '47', '61', '65',\n",
       "       '36', '66', '43', '9', '72', '59', '6', '27', '64', '23', '71',\n",
       "       '44', '62', '63', '70', '1', '53', '77', '74', '5', '86', '84',\n",
       "       '75', '87', '67', '81', '78'], dtype=object)"
      ]
     },
     "execution_count": 1395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all spaces (leading, trailing, and in the middle)\n",
    "cleaned_data['Age'] = cleaned_data['Age'].str.replace(' ', '', regex=True)\n",
    "\n",
    "# Replace values with \"month\" to '1'\n",
    "cleaned_data['Age'] = cleaned_data['Age'].replace(r'.*month.*', '1', regex=True)\n",
    "\n",
    "# if there is an s next to a digit then leave the digit\n",
    "cleaned_data['Age'] = cleaned_data['Age'].str.replace(r'(\\d)s', r'\\1', regex=True)\n",
    "\n",
    "# If a value contains \"to\", \"&\", or \"or\", conserve just the first two digits of that value\n",
    "cleaned_data['Age'] = cleaned_data['Age'].str.replace(r'(\\d{1,2})\\s*(to|&|or|,)\\s*\\d+', r'\\1', regex=True)\n",
    "\n",
    "# Fill NaN values in 'Age' column with 'Unknown'\n",
    "cleaned_data['Age'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "# Replace all values that aren't one or two digit numbers with \"Invalid\"\n",
    "cleaned_data['Age'] = cleaned_data['Age'].apply(lambda x: x if x.isdigit() and len(x) <= 2 else 'Invalid')\n",
    "\n",
    "\n",
    "uniq_val_age = cleaned_data['Age'].unique()\n",
    "uniq_val_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1396,
   "id": "ffbe016f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    57.0\n",
       "1    11.0\n",
       "2    48.0\n",
       "3     NaN\n",
       "4     NaN\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 1396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'Age' column to integers, replacing \"Invalid\" with pd.NA\n",
    "cleaned_data['Age'] = pd.to_numeric(cleaned_data['Age'], errors='coerce')\n",
    "cleaned_data['Age'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e196ddcc",
   "metadata": {},
   "source": [
    "## 2.9 Cleaning Fatal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1397,
   "id": "493bf2d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464 ['N' 'Y' nan 'M' 'UNKNOWN' '2017' ' N' 'N '] 7\n"
     ]
    }
   ],
   "source": [
    "#FATAL\n",
    "nat_count_fatal = cleaned_data['Fatal_(Y/N)'].isna().sum()\n",
    "uniq_val_fatal = cleaned_data['Fatal_(Y/N)'].unique()\n",
    "num_uniq_fatal = cleaned_data['Fatal_(Y/N)'].nunique()\n",
    "print(nat_count_fatal, uniq_val_fatal, num_uniq_fatal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1398,
   "id": "b7c8740f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'Unknown'], dtype=object)"
      ]
     },
     "execution_count": 1398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Remove all spaces and convert to lowercase\n",
    "cleaned_data['Fatal_(Y/N)'] = cleaned_data['Fatal_(Y/N)'].str.replace(' ', '').str.lower()\n",
    "\n",
    "# 2) Replace specific unwanted values with NaN\n",
    "cleaned_data['Fatal_(Y/N)'].replace({'m': np.nan, 'unknown': np.nan, '2017': np.nan}, inplace=True)\n",
    "\n",
    "# 3) Group all \"n\" under \"No\", all \"y\" under \"Yes\", and the rest under \"Unknown\"\n",
    "cleaned_data['Fatal_(Y/N)'] = cleaned_data['Fatal_(Y/N)'].replace({'n': 'No', 'y': 'Yes'}).fillna('Unknown')\n",
    "\n",
    "# Display unique values in the 'Fatal (Y/N)' column after transformation\n",
    "cleaned_data['Fatal_(Y/N)'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61876a43",
   "metadata": {},
   "source": [
    "## 2.10 Cleaning Injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1399,
   "id": "3456bf55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 ['No injury to occupant, outrigger canoe and paddle damaged'\n",
      " 'Minor injury to left thigh'\n",
      " 'Injury to left lower leg from surfboard skeg' ...\n",
      " 'No injury to occupants. They shot shark, then it capsized their skiff. PROVOKED INCIDENT'\n",
      " 'Right posterior thigh bitten'\n",
      " 'Severe abrasion when shark swam between his legs'] 3461\n"
     ]
    }
   ],
   "source": [
    "#INJURY\n",
    "nat_count_injury = cleaned_data['Injury'].isna().sum()\n",
    "uniq_val_injury = cleaned_data['Injury'].unique()\n",
    "num_uniq_injury = cleaned_data['Injury'].nunique()\n",
    "print(nat_count_injury, uniq_val_injury, num_uniq_injury)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1400,
   "id": "65f75b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3446,\n",
       " array(['no injury to occupant, outrigger canoe and paddle damaged',\n",
       "        'minor injury to left thigh',\n",
       "        'injury to left lower leg from surfboard skeg',\n",
       "        'minor injury to lower leg',\n",
       "        'lacerations to leg & hand shark provoked incident',\n",
       "        'no injury, board bitten', 'fatal',\n",
       "        'minor injury to foot. provoked incident', 'lower left leg bitten',\n",
       "        'minor injury to foot'], dtype=object))"
      ]
     },
     "execution_count": 1400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Filling missing values in 'Injury' column with 'unknown'\n",
    "cleaned_data['Injury'] = cleaned_data['Injury'].fillna('unknown')\n",
    "\n",
    "# Step 2: Converting all text in 'Injury' column to lower case\n",
    "cleaned_data['Injury'] = cleaned_data['Injury'].str.lower()\n",
    "\n",
    "# Displaying unique values and number of unique values after these steps\n",
    "uniq_val_injury_after = cleaned_data['Injury'].unique()\n",
    "num_uniq_injury_after = cleaned_data['Injury'].nunique()\n",
    "\n",
    "num_uniq_injury_after, uniq_val_injury_after[:10]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "id": "994d6918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3332,\n",
       " array(['no injury to occupant outrigger canoe and paddle damaged',\n",
       "        'minor injury to left thigh',\n",
       "        'injury to left lower leg from surfboard skeg',\n",
       "        'minor injury to lower leg',\n",
       "        'lacerations to leg hand shark provoked incident',\n",
       "        'no injury board bitten', 'fatal',\n",
       "        'minor injury to foot provoked incident', 'lower left leg bitten',\n",
       "        'minor injury to foot'], dtype=object))"
      ]
     },
     "execution_count": 1401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Step 3: Remove Punctuation\n",
    "cleaned_data['Injury'] = cleaned_data['Injury'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Step 4: Remove Extra Whitespace\n",
    "cleaned_data['Injury'] = cleaned_data['Injury'].str.strip()\n",
    "cleaned_data['Injury'] = cleaned_data['Injury'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Displaying unique values and number of unique values after these steps\n",
    "uniq_val_injury_after = cleaned_data['Injury'].unique()\n",
    "num_uniq_injury_after = cleaned_data['Injury'].nunique()\n",
    "\n",
    "num_uniq_injury_after, uniq_val_injury_after[:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1402,
   "id": "7d6cadb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Injury_Category\n",
       "Other non-fatal attacks    1652\n",
       "Bitten                     1199\n",
       "Fatal                      1026\n",
       "Laceration                  791\n",
       "No Injury                   754\n",
       "Minor Injury                115\n",
       "Unknown                      25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Updating the categorization function to consider the 'Fatal_(Y/N)' column for categorizing fatal injuries\n",
    "def categorize_injury(row):\n",
    "    if row['Fatal_(Y/N)'].lower() == 'yes':\n",
    "        return 'Fatal'\n",
    "    text = str(row['Injury'])\n",
    "    if 'no injury' in text:\n",
    "        return 'No Injury'\n",
    "    elif 'minor injury' in text or 'minor damage' in text:\n",
    "        return 'Minor Injury'\n",
    "    elif 'laceration' in text:\n",
    "        return 'Laceration'\n",
    "    elif 'bitten' in text or 'bite' in text:\n",
    "        return 'Bitten'\n",
    "    elif 'unknown' in text:\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return 'Other non-fatal attacks'\n",
    "\n",
    "# Applying the updated categorization function to the 'Injury' column\n",
    "cleaned_data['Injury_Category'] = cleaned_data.apply(categorize_injury, axis=1)\n",
    "\n",
    "# Displaying the distribution of the injury categories after refactoring\n",
    "injury_category_distribution = cleaned_data['Injury_Category'].value_counts()\n",
    "injury_category_distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5afcdfa",
   "metadata": {},
   "source": [
    "## 2.11 Cleaning Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1403,
   "id": "529cec8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2282 ['White shark' nan '2 m shark' ...\n",
      " 'Fishermen recovered partial remains from shark a week later'\n",
      " \"1.8 m to 2.7 m [6' to 9'] shark\" 'Tiger shark, 3.9 m'] 1504\n"
     ]
    }
   ],
   "source": [
    "#SPECIES\n",
    "nat_count_species = cleaned_data['Species_'].isna().sum()\n",
    "uniq_val_species = cleaned_data['Species_'].unique()\n",
    "num_uniq_species = cleaned_data['Species_'].nunique()\n",
    "print(nat_count_species, uniq_val_species, num_uniq_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1405,
   "id": "8eab6b02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490,\n",
       " array(['white shark', 'unknown', '2 m shark', 'tiger shark, 3m',\n",
       "        'tiger shark', \"lemon shark, 3'\", \"bull shark, 6'\",\n",
       "        'grey reef shark', 'invalid incident', 'tawny nurse shark, 2m'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 1405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Filling missing values in 'Species_' column with 'unknown'\n",
    "cleaned_data['Species_'] = cleaned_data['Species_'].fillna('unknown')\n",
    "\n",
    "# Step 2: Converting all text in 'Species_' column to lower case\n",
    "cleaned_data['Species_'] = cleaned_data['Species_'].str.lower()\n",
    "\n",
    "# Displaying unique values and number of unique values after these steps\n",
    "uniq_val_species_after = cleaned_data['Species_'].unique()\n",
    "num_uniq_species_after = cleaned_data['Species_'].nunique()\n",
    "\n",
    "num_uniq_species_after, uniq_val_species_after[:10]  # Displaying first 10 unique values for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1424,
   "id": "ea5f43cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Species_\n",
       "unknown                                               2283\n",
       "white shark                                            157\n",
       "shark involvement prior to death was not confirmed     105\n",
       "invalid                                                 91\n",
       "shark involvement not confirmed                         87\n",
       "tiger shark                                             69\n",
       "bull shark                                              49\n",
       "4' shark                                                40\n",
       "6' shark                                                38\n",
       "questionable incident                                   37\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_species = cleaned_data['Species_'].value_counts().head(10)\n",
    "top_10_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1516,
   "id": "ecca838c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(834,\n",
       " array(['white shark', 'unknown', '2 m shark', 'tiger shark, 3m',\n",
       "        'tiger shark', \"lemon shark, 3'\", \"6' shark\", 'grey reef shark',\n",
       "        'invalid incident', 'tawny nurse shark, 2m',\n",
       "        'shark involvement not confirmed', 'questionable', '3 m shark',\n",
       "        'white shark, 3.5 m', 'white shark, 2.5 m', 'juvenile bull shark',\n",
       "        'bull shark', \"12' shark\", 'wobbegong shark', '3.5 m shark',\n",
       "        '1.8 m shark', 'blacktip shark',\n",
       "        'juvenile white shark,  2.7 to 3.2 m', 'bull shark, 2 m',\n",
       "        'possibly a wobbegong',\n",
       "        'injury believed caused by an eel, not a shark',\n",
       "        'galapagos shark?', '2m shark', 'bull shark, 3 m ',\n",
       "        'grey reef shark. 2 m', 'small shark', 'wobbegong shark?',\n",
       "        'juvenile nurse shark', \"5' shark\", 'tiger shark, female',\n",
       "        'some drowned but other may have been killed by blue sharks',\n",
       "        'white shark, 4.6 m', 'cookiecutter shark', 'wobbegong shark, 1 m',\n",
       "        'white shark, 4.5 m', 'spinner shark, 4 to 5 feet',\n",
       "        'tiger shark, 8 to 10 feet', \"8' shark\",\n",
       "        'death may have been due to drowning', \"4' shark\",\n",
       "        'porbeagle, 1.5 m', 'white shark, 3.5m', 'white shark, 3 to 3.5m ',\n",
       "        'nurse shark', 'white shark, 3 m'], dtype=object))"
      ]
     },
     "execution_count": 1516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the groups based on specific strings\n",
    "groups = {\n",
    "    \"4' shark\": [\"4'\"],\n",
    "    \"5' shark\": [\"5'\"],\n",
    "    \"6' shark\": [\"6'\"],\n",
    "    \"8' shark\": [\"8'\"],\n",
    "    \"10' shark\": [\"10'\"],\n",
    "    \"12' shark\": [\"12'\"]\n",
    "}\n",
    "\n",
    "# Defining a function to assign groups based on the presence of specific strings\n",
    "def assign_group(text):\n",
    "    text = str(text).lower()\n",
    "    for group, strings in groups.items():\n",
    "        for string in strings:\n",
    "            if string in text:\n",
    "                return group\n",
    "    return text  # Return the original text if no specific string is found\n",
    "\n",
    "# Applying the function to the 'Species_' column\n",
    "cleaned_data['Species_Grouped'] = cleaned_data['Species_'].apply(assign_group)\n",
    "\n",
    "# Displaying unique values and number of unique values after grouping\n",
    "uniq_val_species_grouped = cleaned_data['Species_Grouped'].unique()\n",
    "num_uniq_species_grouped = cleaned_data['Species_Grouped'].nunique()\n",
    "\n",
    "num_uniq_species_grouped, uniq_val_species_grouped[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1518,
   "id": "74bb08e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Species_Cleaned\n",
       "Unknown                            2485\n",
       "Unidentified Shark                  863\n",
       "White shark                         621\n",
       "Tiger shark                         277\n",
       "Shark involvement not confirmed     220\n",
       "Bull shark                          169\n",
       "Nurse shark                          94\n",
       "4' shark                             70\n",
       "5' shark                             66\n",
       "Whaler shark                         66\n",
       "Blacktip shark                       63\n",
       "Mako shark                           53\n",
       "6' shark                             50\n",
       "Wobbegong                            49\n",
       "Reef shark                           49\n",
       "Hammerhead                           44\n",
       "Raggedtooth shark                    43\n",
       "Spinner shark                        43\n",
       "Blue shark                           40\n",
       "Lemon shark                          35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Defining a function to extract shark species from the text\n",
    "\n",
    "def extract_shark_species(text):\n",
    "    known_species = [\n",
    "        'white shark', 'tiger shark', 'bull shark', 'blacktip shark', 'nurse shark',\n",
    "        'wobbegong', 'lemon shark', 'grey reef shark', 'hammerhead', 'whaler shark',\n",
    "        'reef shark', 'mako shark', 'blue shark', 'sand tiger shark', 'carpet shark',\n",
    "        'zambesi shark', 'raggedtooth shark', 'spinner shark', 'silky shark', 'dusky shark',\n",
    "        'bronze whaler', 'galapagos shark', 'sevengill shark', 'angel shark', 'goblin shark',\n",
    "        'sandbar shark', 'dogfish', 'gill shark', 'thresher shark',  \"4' shark\", \"5' shark\", \"6' shark\",\n",
    "        \"8' shark\", \"10' shark\", \"12' shark\"\n",
    "    ]\n",
    "    for species in known_species:\n",
    "        if species in text:\n",
    "            return species.capitalize()\n",
    "    if 'not confirmed'  in text:\n",
    "        return 'Shark involvement not confirmed'\n",
    "    elif 'shark' in text:\n",
    "        return 'Unidentified Shark'\n",
    "    return 'Unknown'\n",
    "\n",
    "# Applying the extraction function to the 'Species_' column\n",
    "cleaned_data['Species_Cleaned'] = cleaned_data['Species_'].apply(extract_shark_species)\n",
    "\n",
    "# Displaying the distribution of the cleaned species\n",
    "species_distribution = cleaned_data['Species_Cleaned'].value_counts()\n",
    "species_distribution.head(20)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e94b4",
   "metadata": {},
   "source": [
    "## 2.12 Saving into .CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1520,
   "id": "757fa306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the CSV file\n",
    "csv_file_path = \"/Users/mairagutierrez/Documents/Ironhack/PROJECTS/project--I/data/cleaning.csv\"\n",
    "\n",
    "# Export the clean data to a CSV file\n",
    "cleaned_data.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133aad29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
